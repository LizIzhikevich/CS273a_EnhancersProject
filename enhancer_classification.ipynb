{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all the cells in this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate one-hot encoding of 6-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bases = ['G', 'C', 'T', 'A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_6_mers = sorted([\n",
    "    ''.join(mer)\n",
    "    for mer in list(itertools.product(bases, repeat = 6))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_6mer(sixmer):\n",
    "    sixmer = sixmer.upper()\n",
    "    index = sixmer_indices[sixmer]\n",
    "    return [\n",
    "        1 if i == index else 0\n",
    "        for i in range(len(sixmer_indices))\n",
    "    ]\n",
    "\n",
    "def kmers(sequence, k):\n",
    "    return [\n",
    "        sequence[i:i+k]\n",
    "        for i in range(len(sequence) - k + 1)\n",
    "    ]\n",
    "\n",
    "def encode_sequence(sequence):\n",
    "    kmer_dict = {}\n",
    "    for kmer in kmers(sequence, 6):\n",
    "        if kmer in kmer_dict:\n",
    "            kmer_dict[kmer] += 1\n",
    "        else:\n",
    "            kmer_dict[kmer] = 1\n",
    "    \n",
    "    return [\n",
    "        kmer_dict[sixmer] if sixmer in kmer_dict else 0\n",
    "        for sixmer in possible_6_mers\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labels\n",
    "\n",
    "Expects a list of tuples of `(sequence, boolean for if it's an enhancer, list of tissues)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('enhancer_features', 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify enhancer prediction task\n",
    "\n",
    "Specify what gets positive labels and what gets negative labels. Options are `forebrain`, `midbrain`, `limb`, `random`.\n",
    "\n",
    "For example:\n",
    "* Positive label `forebrain` with negative label `random` tries to classify whether a sequence is an enhancer in the forebrain region vs. anything else.\n",
    "* Positive label `forebrain` with negative label `midbrain` tries to classify enhancers in the forebrain vs. enhancers in the midbrain. It will ignore any enhancers in both regions or sequences that aren't enhancers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_Y(enhancer, tissues, pos_label, neg_label):\n",
    "    if pos_label in tissues and neg_label in tissues:\n",
    "        return None\n",
    "    if pos_label in tissues:\n",
    "        return 1\n",
    "    if neg_label in tissues:\n",
    "        return 0\n",
    "    if pos_label == 'random':\n",
    "        return 1\n",
    "    if neg_label == 'random':\n",
    "        return 0\n",
    "    return None\n",
    "    \n",
    "def get_X_Y(data, pos_label, neg_label):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for d in tqdm(data):\n",
    "        y = get_Y(d[1], d[2], pos_label, neg_label)\n",
    "        if y is not None:\n",
    "            X.append(encode_sequence(d[0]))\n",
    "            Y.append(y)\n",
    "    \n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test an SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POSITIVE_LABEL = 'forebrain'\n",
    "NEGATIVE_LABEL = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_X_Y(labels, POSITIVE_LABEL, NEGATIVE_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aurocs = []\n",
    "for train_index, test_index in tqdm(kf.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    clf = SVC(gamma='auto', probability=True)\n",
    "    clf.fit(X_train, Y_train) \n",
    "    \n",
    "    preds_with_scores = clf.predict_proba(X_test)\n",
    "    aurocs.append(roc_auc_score(Y_test, preds_with_scores))\n",
    "    \n",
    "print('Average auROC: {}'.format(np.mean(aurocs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: generate precision recall curves (see https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: repeat the above five K fold training cells for midbrain vs. random, limb vs. random, forebrain vs. limb, midbrain vs. limb, forebrain vs. midbrain. Look at figure 2 in the paper."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
